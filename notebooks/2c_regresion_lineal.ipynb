{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeAutomatizado/blob/master/notebooks/2c_regresion_lineal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "Curso: [Aprendizaje Automatizado](http://turing.iimas.unam.mx/~gibranfp/cursos/aprendizaje_automatizado). Profesor: [Gibran Fuentes Pineda](https://turing.iimas.unam.mx/~gibranfp/). Ayudantes: [Bere](https://turing.iimas.unam.mx/~bereml/) y [Ricardo](https://turing.iimas.unam.mx/~ricardoml/) Montalvo Lezama.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "En esta libreta veremos un ejemplo paso a paso del modelo de regresión lineal con dos atributos de entrada y una salida. Emplearemos un conjunto de calificaciones de alumnos posgrado que tomaron primero el curso de Aprendizaje de Automatizado y después el curso de Aprendizaje Profundo. El conjunto tiene dos atributos: la calificación obtenida en el curso de Aprendizaje de Automatizado y el número de horas de estudio para el examen del curso de Aprendizaje Profundo. Como salida se tiene la calificación obtenida en examen de Aprendizaje Profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipympl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8bbd5eb17d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://github.com/matplotlib/jupyter-matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# descomentar la siguiente linea y correr de nuevo toda la libreta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'widget'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-101>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3513\u001b[0m                 \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3515\u001b[0;31m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3516\u001b[0m         \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_inline_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# when this function runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m \u001b[0;31m# Set up the backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m \u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;31m# Just to be safe.  Interactive mode can be turned on without\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0mbackend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbackend_mod\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mbackend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_bases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mrequired_framework\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_required_interactive_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_mod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/iap/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipympl'"
     ]
    }
   ],
   "source": [
    "# para correr con widgets en local instalar jupyter-matplotlib\n",
    "# https://github.com/matplotlib/jupyter-matplotlib\n",
    "# descomentar la siguiente linea y correr de nuevo toda la libreta\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leamos con Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeAutomatizado/master/data/califs.csv'\n",
    "df = pd.read_csv(URL)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversión de numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:2].values\n",
    "print(x.shape)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df.iloc[:,2].values\n",
    "print(y_true.shape)\n",
    "y_true[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construcción de la matriz de diseño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones([x.shape[0], 1])\n",
    "x = np.hstack([ones, x])\n",
    "print(x.shape)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos número de atributos y ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = x.shape\n",
    "n, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploración\n",
    "\n",
    "Grafiquemos para tener una idea de la distribución de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:, 1], x[:, 2], y_true,\n",
    "           color='tab:blue')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hipótesis\n",
    "\n",
    "Recordemos que dado un conjunto de ejemplos con atributos $x_1, x_2$ y salida $y$, la hipótesis de regresión lineal considerando un plano está dada por:\n",
    "\n",
    "$$ \\hat{y} = \\theta_0 + x_1 \\theta_1 + x_2 \\theta_2 $$\n",
    "\n",
    "donde $\\theta_0, \\theta_1, \\theta_2$ son parámetros del modelo y $\\hat{y}$ la salida predicha. Empleando la matriz de diseño, podemos expresar la hipótesis en su forma vectorial para todo el conjunto:\n",
    "\n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{x} \\mathbf{\\theta}^T $$\n",
    "\n",
    "Nuestro trabajo consiste en estimar (aprender) los parámetros $\\theta_0, \\theta_1, \\theta_2$. Por el momento supongamos que un oráculo nos regalo los siguientes valores para los parámetros y hagamos inferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.array([1.7071569, 0.13335178, 0.41122846])\n",
    "\n",
    "y_pred = []\n",
    "for i in range(n):\n",
    "    y_p = theta[0] + x[i, 1] * theta[1] + x[i, 2] * theta[2]\n",
    "    y_pred.append(y_p)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementando la forma vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x @ theta.T\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos el plano correspondiente a los parámetros propuestos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(x[:,1].min(), x[:,1].max(), 2)\n",
    "x2 = np.linspace(x[:,2].min(), x[:,2].max(), 2)\n",
    "x1, x2 = np.meshgrid(x1, x2)\n",
    "y_pred = theta[0] + theta[1] * x1 + theta[2] * x2\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(x1, x2, y_pred, rstride=1, cstride=1, alpha=0.5)\n",
    "ax.plot(x[:, 1], x[:, 2], y_true, 'b.')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Función de pérdida\n",
    "\n",
    "La pérdida para este modelo es el error cuadrático medio y queda expresado de la siguiente manera:\n",
    "\n",
    "$$ E(\\mathbf{\\theta}) = \\frac{1}{2n}  \\sum_{i=1}^{n}{(\\hat{y}^{(i)} - y^{(i)})^2} $$\n",
    "\n",
    "en su forma vectorial:\n",
    "\n",
    "$$ E(\\mathbf{\\theta}) = \\frac{1}{2n} (\\mathbf{\\hat{y}} - \\mathbf{y})^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$\n",
    "\n",
    "Para los parámetros propuestos, la pérdida se puede implementar como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recomputamos las predicciones de los datos\n",
    "y_pred = x @ theta.T\n",
    "\n",
    "loss = 0\n",
    "for i in range(n):\n",
    "    loss += (y_pred[i] - y_true[i])**2\n",
    "loss /= 2 * n\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y en su forma vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Descenso por gradiente\n",
    "\n",
    "![graddes](https://ml-cheatsheet.readthedocs.io/en/latest/_images/gradient_descent_demystified.png)\n",
    "\n",
    "Imagen tomada de https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo del descenso por gradiente se basa en el gradiente de la pérdida respecto de los parámetros:\n",
    "\n",
    "$$ \\frac{\\partial E(\\theta)}{\\partial \\theta_j} = \\frac{1}{n} \\sum_{i=1}^{n}{(\\hat{y}^{(i)} - y^{(i)})x^{(i)}_j} $$\n",
    "\n",
    "en su forma vectorial:\n",
    "\n",
    "$$ \\Delta E(\\mathbf{\\theta}) = \\frac{1}{n} \\mathbf{x}^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$\n",
    "\n",
    "Para los parámetros propuestos, el cómputo gradiente se puede implementar como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = [0, 0, 0]\n",
    "for j in range(d):\n",
    "    for i in range(n):\n",
    "        grad[j] += (y_pred[i] - y_true[i]) * x[i, j]\n",
    "    grad[j] /= n\n",
    "np.array(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y en su forma vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = (x.T @ (y_pred - y_true)) / n\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base en el gradiente, la regla de actualización del descenso por gradiente queda expresada como:\n",
    "\n",
    "$$ \\theta_d^{[t+1]} \\leftarrow \\theta_d^{[t]}  - \\alpha \\frac{\\partial E(\\theta^{[t]})}{\\partial \\mathbf{\\theta}_d^{[t]}} $$\n",
    "\n",
    "mientras que su forma vectorial:\n",
    "\n",
    "$$ \\mathbf{\\theta}^{[t+1]} \\leftarrow \\mathbf{\\theta}^{[t]}  - \\alpha \\Delta E(\\mathbf{\\theta}^{[t]}) $$\n",
    "\n",
    "Para los parámetros propuestos y datos, el gradiente se puede implementar como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "\n",
    "theta_next = []\n",
    "for t, g in zip(theta, grad):\n",
    "    t_next = t - alpha * g\n",
    "    theta_next.append(t_next)\n",
    "theta = np.array(theta_next)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y su forma vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reniniciamos los parámetros\n",
    "theta = np.array([1.7071569, 0.13335178, 0.41122846])\n",
    "\n",
    "theta = theta - alpha * grad\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento\n",
    "\n",
    "Realicemos 3 pasos del descenso por gradiente estocástico con lotes de 2 de forma manual. Primero inicialicemos de nuevo nuestros parámetros y tasa de aprendizaje: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "np.random.seed(0)\n",
    "theta = np.random.normal(0, 1, d)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computemos la pérdida total de los datos y mantengamos un historial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x @ theta.T\n",
    "loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "loss_hist = [loss]\n",
    "loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Paso 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Selección del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [0, 24]\n",
    "n_batch = len(examples)\n",
    "x_batch = x[examples]\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_batch = y_true[examples]\n",
    "y_true_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Predicciones:\n",
    "\n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{x} \\mathbf{\\theta}^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_batch = x_batch @ theta.T\n",
    "y_pred_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Pérdida:\n",
    "$$ E(\\mathbf{\\theta}) = \\frac{1}{2n} (\\mathbf{\\hat{y}} - \\mathbf{y})^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_batch = (y_pred_batch - y_true_batch).T @ (y_pred_batch - y_true_batch) / (2 * n_batch)\n",
    "loss_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Gradiente:\n",
    "\n",
    "$$ \\Delta E(\\mathbf{\\theta}) = \\frac{1}{n} \\mathbf{x}^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_batch = (x_batch.T @ (y_pred_batch - y_true_batch)) / n_batch\n",
    "grad_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) Parámetros actualizados:\n",
    "\n",
    "$$ \\mathbf{\\theta}^{[t+1]} \\leftarrow \\mathbf{\\theta}^{[t]}  - \\alpha \\Delta E(\\mathbf{\\theta}^{[t]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta - alpha * grad_batch\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F) Actualicemos el historial de pérdidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x @ theta.T\n",
    "loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "loss_hist.append(loss)\n",
    "loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Paso 2\n",
    "\n",
    "A) Selección del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [8, 32]\n",
    "n_batch = len(examples)\n",
    "x_batch = x[examples]\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_batch = y_true[examples]\n",
    "y_true_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Predicciones:\n",
    "\n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{x} \\mathbf{\\theta}^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_batch = x_batch @ theta.T\n",
    "y_pred_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Pérdida:\n",
    "\n",
    "$$ E(\\mathbf{\\theta}) = \\frac{1}{2n} (\\mathbf{\\hat{y}} - \\mathbf{y})^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_batch = (y_pred_batch - y_true_batch).T @ (y_pred_batch - y_true_batch) / (2 * n_batch)\n",
    "loss_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Gradiente:\n",
    "\n",
    "$$ \\Delta E(\\mathbf{\\theta}) = \\frac{1}{n} \\mathbf{x}^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_batch = (x_batch.T @ (y_pred_batch - y_true_batch)) / n_batch\n",
    "grad_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) Parámetros actualizados:\n",
    "\n",
    "$$ \\mathbf{\\theta}^{[t+1]} \\leftarrow \\mathbf{\\theta}^{[t]}  - \\alpha \\Delta E(\\mathbf{\\theta}^{[t]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta - alpha * grad_batch\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F) Actualicemos el historial de pérdidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x @ theta.T\n",
    "loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "loss_hist.append(loss)\n",
    "loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Paso 3\n",
    "\n",
    "A) Selección del lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [16, 40]\n",
    "n_batch = len(examples)\n",
    "x_batch = x[examples]\n",
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_batch = y_true[examples]\n",
    "y_true_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Predicciones:\n",
    "\n",
    "$$ \\mathbf{\\hat{y}} = \\mathbf{x} \\mathbf{\\theta}^T $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_batch = x_batch @ theta.T\n",
    "y_pred_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Pérdida:\n",
    "\n",
    "$$ E(\\mathbf{\\theta}) = \\frac{1}{2n} (\\mathbf{\\hat{y}} - \\mathbf{y})^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_batch = (y_pred_batch - y_true_batch).T @ (y_pred_batch - y_true_batch) / (2 * n_batch)\n",
    "loss_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Gradiente:\n",
    "\n",
    "$$ \\Delta E(\\mathbf{\\theta}) = \\frac{1}{n} \\mathbf{x}^T (\\mathbf{\\hat{y}} - \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_batch = (x_batch.T @ (y_pred_batch - y_true_batch)) / n_batch\n",
    "grad_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) Parámetros actualizados:\n",
    "\n",
    "$$ \\mathbf{\\theta}^{[t+1]} \\leftarrow \\mathbf{\\theta}^{[t]}  - \\alpha \\Delta E(\\mathbf{\\theta}^{[t]}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta - alpha * grad_batch\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F) Actualicemos el historial de pérdidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x @ theta.T\n",
    "loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "loss_hist.append(loss)\n",
    "loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es un implementación sencilla del descenso por gradiente en su forma vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y_true, alpha=0.01, steps=50):\n",
    "    # ejemplos, atributos\n",
    "    n, d = x.shape\n",
    "    # inicialización de parámetros\n",
    "    theta = np.random.normal(0, 1, d)\n",
    "    # hostorial de pérdidas\n",
    "    loss_hist = []\n",
    "    # ciclo de entrenamiento\n",
    "    for _ in range(steps):\n",
    "        # cómputo de la hipótesis\n",
    "        y_pred = x @ theta.T\n",
    "        # cómputo de la pérdida\n",
    "        loss = (y_pred - y_true).T @ (y_pred - y_true) / (2 * n)\n",
    "        # cómputo del gradiente\n",
    "        grad = (x.T @ (y_pred - y_true)) / n\n",
    "        # actualización de parámetros\n",
    "        theta = theta - alpha * grad\n",
    "        # hostorial de pérdida\n",
    "        loss_hist.append(loss)\n",
    "    return theta, loss_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenemos nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "theta, loss_hist = train(x, y_true)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos la evolución de la pérdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(loss_hist)), loss_hist, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tarea moral\n",
    "\n",
    "Modificar esta libreta para implementar el descenso por gradiente estocástico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![xkcd-linreg](https://imgs.xkcd.com/comics/linear_regression.png)\n",
    "\n",
    "https://xkcd.com/1725/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
